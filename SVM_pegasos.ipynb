{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Linear Support Vector Machine (SVM) classifier from scratch\n",
        "using stochastic gradient descent (SGD)  \n",
        "\n"
      ],
      "metadata": {
        "id": "DKd77uQDiPo7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM:**   \n",
        "$\\frac{1}{n} \\sum_{i=1}^n \\left[ 1 - y_i(x_i^t \\beta + \\alpha) \\right]_+ + \\frac{\\lambda}{2} \\|\\beta\\|^2$    \n",
        "Loss + Penalty  "
      ],
      "metadata": {
        "id": "wtB9i1xgvkND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pegasos Algorithm:**  \n",
        "1. Initialize $\\beta = 0_{p \\times 1}$, $\\alpha_1 = 0$, and $t = 0$\n",
        "\n",
        "2. For epoch $= 1, 2, \\ldots, T$ do\n",
        "    - For $i = 1, 2, \\ldots, n$ do\n",
        "        - $t = t + 1$, $\\eta_t = \\frac{1}{\\lambda t}$\n",
        "        - Update $\\beta_{t+1} \\gets \\beta_t - \\eta_t \\Delta_t$\n",
        "        - Update $\\alpha_{t+1} \\gets \\alpha_t - \\eta_t \\delta_t$\n",
        "\n",
        "Here $\\eta_t$ is the learning rate, and $\\Delta_t$ and $\\delta_t$ are the (sub)gradient of $J_i(\\beta, \\alpha)$ when $\\beta = \\beta_t$ and $\\alpha = \\alpha_t$:\n",
        "\n",
        "$J_i(\\beta, \\alpha) = \\frac{\\lambda}{2} \\|\\beta\\|^2 + \\left[ 1 - y_i(x_i^t \\beta + \\alpha) \\right]_+$\n",
        "\n",
        "$\\Delta_t = \\begin{cases}\n",
        "    \\lambda \\beta_t - y_i x_i & \\text{if } y_i (x_i^t \\beta_t + \\alpha_t) < 1 \\\\\n",
        "    \\lambda \\beta_t & \\text{otherwise}\n",
        "\\end{cases}$\n",
        "\n",
        "$\\delta_t = \\begin{cases}\n",
        "    -y_i & \\text{if } y_i (x_i^t \\beta_t + \\alpha_t) < 1 \\\\\n",
        "    0 & \\text{otherwise}\n",
        "\\end{cases}$\n"
      ],
      "metadata": {
        "id": "gTzGVvNHifTp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUxVfxTGHXdg",
        "outputId": "0e408174-e6ff-402c-c4aa-0b986719300c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data Confusion Matrix:\n",
            "[[100   0]\n",
            " [  1  99]]\n",
            "\n",
            "Test Data Confusion Matrix:\n",
            "[[281  19]\n",
            " [ 13 287]]\n",
            "Test Error: 0.0533\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "url = \"train.csv\"\n",
        "train_data = pd.read_csv(url)\n",
        "url = \"test.csv\"\n",
        "test_data = pd.read_csv(url)\n",
        "\n",
        "X_train = train_data.iloc[:, :-1].astype(float).values\n",
        "y_train = train_data.iloc[:, -1].astype(int).values\n",
        "y_train = np.where(y_train == 5, 1, -1)\n",
        "\n",
        "X_test = test_data.iloc[:, :-1].astype(float).values\n",
        "y_test = test_data.iloc[:, -1].astype(int).values\n",
        "y_test = np.where(y_test == 5, 1, -1)\n",
        "\n",
        "\n",
        "def pegasos(X, y, lambda_reg=0.01, epochs=20, seed=42):\n",
        "    np.random.seed(seed)\n",
        "    n, d = X.shape\n",
        "    beta = np.zeros(d)\n",
        "    alpha = 0\n",
        "    t = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        indices = np.random.permutation(n)\n",
        "        for i in indices:\n",
        "            t += 1\n",
        "            eta_t = 1 / (t * lambda_reg)\n",
        "            x_i, y_i = X[i], y[i]\n",
        "            condition = y_i * (np.dot(x_i, beta) + alpha) < 1\n",
        "\n",
        "            if condition:\n",
        "                beta = (1 - eta_t * lambda_reg) * beta + eta_t * y_i * x_i\n",
        "                alpha += eta_t * y_i\n",
        "            else:\n",
        "                beta = (1 - eta_t * lambda_reg) * beta\n",
        "\n",
        "    return beta, alpha\n",
        "\n",
        "lambda_reg = 0.01\n",
        "epochs = 20\n",
        "beta, alpha = pegasos(X_train, y_train, lambda_reg, epochs)\n",
        "\n",
        "def predict(X, beta, alpha):\n",
        "    return np.where(np.dot(X, beta) + alpha > 0, 1, -1)\n",
        "\n",
        "y_train_pred = predict(X_train, beta, alpha)\n",
        "y_test_pred = predict(X_test, beta, alpha)\n",
        "\n",
        "\n",
        "print(\"Training Data Confusion Matrix:\")\n",
        "print(confusion_matrix(y_train, y_train_pred))\n",
        "\n",
        "print(\"\\nTest Data Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_test_pred))\n",
        "\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_error = 1 - test_accuracy\n",
        "print(f\"Test Error: {test_error:.4f}\")"
      ]
    }
  ]
}